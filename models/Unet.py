
#imports
import torch as t
import torch.nn as nn
from torch.nn import Transformer
import math
import numpy as np
import pandas as pd
import torch.nn.functional as F

import torch
import torch.nn as nn

class DoubleConv(nn.Module):
    def __init__(self, in_c, out_c):
        super().__init__()
        self.conv = nn.Sequential(
            nn.Conv2d(in_c, out_c, 3, padding=1),
            nn.BatchNorm2d(out_c),
            nn.ReLU(inplace=True),
            nn.Conv2d(out_c, out_c, 3, padding=1),
            nn.BatchNorm2d(out_c),
            nn.ReLU(inplace=True),
        )

    def forward(self, x):
        return self.conv(x)

class UNet(nn.Module):
    def __init__(self):
        super().__init__()

        self.d1 = DoubleConv(3, 64)
        self.d2 = DoubleConv(64, 128)
        self.d3 = DoubleConv(128, 256)
        self.d4 = DoubleConv(256, 512)

        self.pool = nn.MaxPool2d(2)

        self.bottleneck = DoubleConv(512, 1024)

        self.u4 = nn.ConvTranspose2d(1024, 512, 2, stride=2)
        self.u3 = nn.ConvTranspose2d(512, 256, 2, stride=2)
        self.u2 = nn.ConvTranspose2d(256, 128, 2, stride=2)
        self.u1 = nn.ConvTranspose2d(128, 64, 2, stride=2)

        self.c4 = DoubleConv(1024, 512)
        self.c3 = DoubleConv(512, 256)
        self.c2 = DoubleConv(256, 128)
        self.c1 = DoubleConv(128, 64)

        self.out = nn.Conv2d(64, 1, 1)

    def forward(self, x):
        d1 = self.d1(x)
        d2 = self.d2(self.pool(d1))
        d3 = self.d3(self.pool(d2))
        d4 = self.d4(self.pool(d3))

        b = self.bottleneck(self.pool(d4))

        x = self.c4(torch.cat([self.u4(b), d4], dim=1))
        x = self.c3(torch.cat([self.u3(x), d3], dim=1))
        x = self.c2(torch.cat([self.u2(x), d2], dim=1))
        x = self.c1(torch.cat([self.u1(x), d1], dim=1))

        #return torch.sigmoid(self.out(x))
        return self.out(x)


def test(x_pxls, y_pxls):
    x = t.randn(3, 3, x_pxls, y_pxls)
    model = UNet()
    preds = model(x)

    if x.shape == preds.shape:
        print(f'test for Tensor size errors is a pass with {[x_pxls, y_pxls]}')
    else:
        print(f'test for tensor size errors is a fail with {[x_pxls, y_pxls]}')

    
if __name__ == '__main__':
    test(160, 160)
    test(160,320)
    test(128,128)
    test(256,256)
    test(512,512)
    test(1024,1024)
 #failed by sizes being different after conv layers